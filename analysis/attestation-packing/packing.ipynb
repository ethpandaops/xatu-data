{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install jupysql clickhouse_sqlalchemy matplotlib python-dotenv pandas seaborn imageio > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import imageio\n",
    "plt.rcParams['figure.dpi'] = 300  # Set high DPI for better quality figures\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_branding(fig, title=None, subtitle=None, title_size=20, subtitle_size=12):\n",
    "    \"\"\"Add branding to a matplotlib figure with logos and optional title/subtitle.\"\"\"\n",
    "    # Create a new figure with extra height for the header\n",
    "    original_size = fig.get_size_inches()\n",
    "    new_height = original_size[1] + 1.2  # Add space for header\n",
    "    \n",
    "    # Create new figure with combined dimensions\n",
    "    branded_fig = plt.figure(figsize=(original_size[0], new_height))\n",
    "    \n",
    "    # Create a gridspec to manage the layout\n",
    "    gs = branded_fig.add_gridspec(2, 1, height_ratios=[1, 5], hspace=0.05)\n",
    "    \n",
    "    # Header area for logos and titles\n",
    "    header_ax = branded_fig.add_subplot(gs[0])\n",
    "    \n",
    "    # Load logos\n",
    "    ethpandaops = plt.imread('../../assets/content/ethpandaops.png')\n",
    "    xatu = plt.imread('../../assets/content/xatu.png')\n",
    "    \n",
    "    # Add logos as inset axes\n",
    "    logo_height = 0.7\n",
    "    left_logo = header_ax.inset_axes([0.02, 0.15, 0.18, logo_height])\n",
    "    right_logo = header_ax.inset_axes([0.82, 0.15, 0.16, logo_height])\n",
    "    \n",
    "    left_logo.imshow(ethpandaops)\n",
    "    right_logo.imshow(xatu)\n",
    "    left_logo.axis('off')\n",
    "    right_logo.axis('off')\n",
    "    \n",
    "    # Add title and subtitle\n",
    "    if title:\n",
    "        header_ax.text(0.5, 0.7, title, fontsize=title_size, fontweight='bold', ha='center', va='center')\n",
    "    if subtitle:\n",
    "        header_ax.text(0.5, 0.3, subtitle, fontsize=subtitle_size, ha='center', va='center')\n",
    "    \n",
    "    header_ax.axis('off')\n",
    "    \n",
    "    # Content area for the original figure\n",
    "    content_ax = branded_fig.add_subplot(gs[1])\n",
    "    \n",
    "    # Draw the original figure to its canvas first\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # Make sure the renderer exists before accessing it\n",
    "    if not hasattr(fig.canvas, 'renderer'):\n",
    "        # Create a renderer if it doesn't exist\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    # Get the image data from the original figure\n",
    "    img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    content_ax.imshow(img)\n",
    "    content_ax.axis('off')\n",
    "    \n",
    "    # Close the original figure to avoid displaying it\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return branded_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    def __init__(self, time_ranges, network):\n",
    "        self.time_ranges = time_ranges\n",
    "        self.network = network\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    [\n",
    "        (\"2025-03-28T12:10:00Z\", \"2025-03-28T18:10:00Z\"),\n",
    "        (\"2025-04-01T05:10:00Z\", \"2025-04-01T11:10:00Z\")\n",
    "    ],\n",
    "    \"hoodi\"\n",
    ")\n",
    "\n",
    "event_date = pd.to_datetime(\"2025-04-01T03:50:00Z\", utc=True)\n",
    "event_date_naive = event_date.tz_localize(None) if event_date.tzinfo is not None else event_date\n",
    "\n",
    "annotations = {\n",
    "    \"2025-03-26T14:37:12Z\": \"Hoodi Electra Fork\",\n",
    "}\n",
    "\n",
    "# Convert annotation timestamps to datetime objects for later use\n",
    "annotation_datetimes = {\n",
    "    datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\")): msg\n",
    "    for ts, msg in annotations.items()\n",
    "}\n",
    "\n",
    "# Print the config contents\n",
    "print(\"config network:\", config.network)\n",
    "print(\"config time ranges:\", config.time_ranges)\n",
    "print(\"event date:\", event_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ClickHouse\n",
    "import os\n",
    "username = os.getenv('XATU_CLICKHOUSE_USERNAME')\n",
    "password = os.getenv('XATU_CLICKHOUSE_PASSWORD')\n",
    "host = os.getenv('XATU_CLICKHOUSE_HOST')\n",
    "\n",
    "\n",
    "db_url = f\"clickhouse+http://{username}:{password}@{host}:443/default?protocol=https\"\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load known validators from the YAML file\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_validators(network):\n",
    "    \"\"\"Load validators from the YAML file for the specified network.\"\"\"\n",
    "    validators_path = Path(f\"../../assets/ethereum/{network}/validators.yaml\")\n",
    "    \n",
    "    if not validators_path.exists():\n",
    "        print(f\"Validators file not found at {validators_path}\")\n",
    "        return {}\n",
    "    \n",
    "    with open(validators_path, 'r') as file:\n",
    "        validators_data = yaml.safe_load(file)\n",
    "    \n",
    "    # Process the validators data\n",
    "    validators_map = {}\n",
    "    for range_str, client in validators_data.items():\n",
    "        if isinstance(range_str, str) and '-' in range_str:\n",
    "            start, end = map(int, range_str.split('-'))\n",
    "            for validator_index in range(start, end + 1):\n",
    "                validators_map[validator_index] = client\n",
    "        elif isinstance(range_str, int):\n",
    "            # Handle single validator case\n",
    "            validators_map[range_str] = client\n",
    "    \n",
    "    return validators_map\n",
    "\n",
    "def get_validator_entity(validator_index, validators_map):\n",
    "    \"\"\"Get the entity/client associated with a validator index.\"\"\"\n",
    "    if validator_index in validators_map:\n",
    "        return validators_map[validator_index]\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_validator_entities(validator_indices, validators_map):\n",
    "    \"\"\"Get entities for multiple validator indices.\"\"\"\n",
    "    return {idx: get_validator_entity(idx, validators_map) for idx in validator_indices}\n",
    "\n",
    "def is_validator_from_entity(validator_index, entity, validators_map):\n",
    "    \"\"\"Check if a validator belongs to a specific entity.\"\"\"\n",
    "    return get_validator_entity(validator_index, validators_map) == entity\n",
    "\n",
    "# Load validators for the configured network\n",
    "validators = load_validators(config.network)\n",
    "print(f\"Loaded {len(validators)} validators for {config.network}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be loading in all the `elaborated_attestations` from the `canonical_beacon_elab_attestations` table\n",
    "# canonical_beacon_elaborated_attestation\n",
    "# #\n",
    "# Contains elaborated attestations from beacon blocks.\n",
    "\n",
    "# Availability\n",
    "# #\n",
    "# Data is partitioned daily on slot_start_date_time for the following networks:\n",
    "\n",
    "# mainnet: 2020-12-01 to 2025-03-10\n",
    "# holesky: 2023-09-23 to 2025-03-11\n",
    "# sepolia: 2022-06-22 to 2025-03-10\n",
    "# Examples\n",
    "# #\n",
    "# Parquet file\n",
    "# Your Clickhouse\n",
    "# EthPandaOps Clickhouse\n",
    "# Columns\n",
    "# #\n",
    "# Name\tType\tDescription\n",
    "# updated_date_time\tDateTime\tWhen this row was last updated\n",
    "# block_slot\tUInt32\tThe slot number of the block containing the attestation\n",
    "# block_slot_start_date_time\tDateTime\tThe wall clock time when the block slot started\n",
    "# block_epoch\tUInt32\tThe epoch number of the block containing the attestation\n",
    "# block_epoch_start_date_time\tDateTime\tThe wall clock time when the block epoch started\n",
    "# position_in_block\tUInt32\tThe position of the attestation in the block\n",
    "# block_root\tFixedString(66)\tThe root of the block containing the attestation\n",
    "# validators\tArray(UInt32)\tArray of validator indices participating in the attestation\n",
    "# committee_index\tLowCardinality(String)\tThe index of the committee making the attestation\n",
    "# beacon_block_root\tFixedString(66)\tThe root of the beacon block being attested to\n",
    "# slot\tUInt32\tThe slot number being attested to\n",
    "# slot_start_date_time\tDateTime\t**\n",
    "# epoch\tUInt32\t**\n",
    "# epoch_start_date_time\tDateTime\t**\n",
    "# source_epoch\tUInt32\tThe source epoch referenced in the attestation\n",
    "# source_epoch_start_date_time\tDateTime\tThe wall clock time when the source epoch started\n",
    "# source_root\tFixedString(66)\tThe root of the source checkpoint in the attestation\n",
    "# target_epoch\tUInt32\tThe target epoch referenced in the attestation\n",
    "# target_epoch_start_date_time\tDateTime\tThe wall clock time when the target epoch started\n",
    "# target_root\tFixedString(66)\tThe root of the target checkpoint in the attestation\n",
    "# meta_client_name\tLowCardinality(String)\tName of the client that generated the event\n",
    "# meta_client_id\tString\tUnique Session ID of the client that generated the event. This changes every time the client is restarted.\n",
    "# meta_client_version\tLowCardinality(String)\tVersion of the client that generated the event\n",
    "# meta_client_implementation\tLowCardinality(String)\tImplementation of the client that generated the event\n",
    "# meta_client_os\tLowCardinality(String)\tOperating system of the client that generated the event\n",
    "# meta_client_ip\tNullable(IPv6)\tIP address of the client that generated the event\n",
    "# meta_client_geo_city\tLowCardinality(String)\tCity of the client that generated the event\n",
    "# meta_client_geo_country\tLowCardinality(String)\tCountry of the client that generated the event\n",
    "# meta_client_geo_country_code\tLowCardinality(String)\tCountry code of the client that generated the event\n",
    "# meta_client_geo_continent_code\tLowCardinality(String)\tContinent code of the client that generated the event\n",
    "# meta_client_geo_longitude\tNullable(Float64)\tLongitude of the client that generated the event\n",
    "# meta_client_geo_latitude\tNullable(Float64)\tLatitude of the client that generated the event\n",
    "# meta_client_geo_autonomous_system_number\tNullable(UInt32)\tAutonomous system number of the client that generated the event\n",
    "# meta_client_geo_autonomous_system_organization\tNullable(String)\tAutonomous system organization of the client that generated the event\n",
    "# meta_network_id\tInt32\tEthereum network ID\n",
    "# meta_network_name\tLowCardinality(String)\tEthereum network name\n",
    "# meta_consensus_version\tLowCardinality(String)\tEthereum consensus client version that generated the event\n",
    "# meta_consensus_version_major\tLowCardinality(String)\tEthereum consensus client major version that generated the event\n",
    "# meta_consensus_version_minor\tLowCardinality(String)\tEthereum consensus client minor version that generated the event\n",
    "# meta_consensus_version_patch\tLowCardinality(String)\tEthereum consensus client patch version that generated the event\n",
    "# meta_consensus_implementation\tLowCardinality(String)\tEthereum consensus client implementation that generated the event\n",
    "# meta_labels\tMap(String, String)\tLabels associated with the event\n",
    "\n",
    "# Load all elaborated attestations for the time period\n",
    "all_attestations = pd.DataFrame()\n",
    "\n",
    "for start_date, end_date in config.time_ranges:\n",
    "    print(f\"Loading attestations for time range: {start_date} to {end_date} for network: {config.network}\")\n",
    "    \n",
    "    attestations_query = text(\"\"\"\n",
    "        SELECT\n",
    "            block_slot,\n",
    "            block_slot_start_date_time,\n",
    "            validators,\n",
    "            committee_index,\n",
    "            slot,\n",
    "            slot_start_date_time,\n",
    "            epoch,\n",
    "            position_in_block\n",
    "        FROM canonical_beacon_elaborated_attestation\n",
    "        WHERE\n",
    "            block_epoch_start_date_time BETWEEN toDateTime(:start_date, 'UTC') AND toDateTime(:end_date, 'UTC')\n",
    "            AND meta_network_name = :network\n",
    "        ORDER BY block_slot ASC, position_in_block ASC\n",
    "    \"\"\")\n",
    "\n",
    "    result = connection.execute(attestations_query, {\n",
    "        \"start_date\": start_date.replace('Z', ''), \n",
    "        \"end_date\": end_date.replace('Z', ''), \n",
    "        \"network\": config.network\n",
    "    })\n",
    "    \n",
    "    current_attestations = pd.DataFrame(result.fetchall(), columns=[\n",
    "        'block_slot', 'block_slot_start_date_time', \n",
    "        'validators', 'committee_index', 'slot', 'slot_start_date_time',\n",
    "        'epoch', 'position_in_block'\n",
    "    ])\n",
    "    \n",
    "    # Parse validators column if it's a string\n",
    "    if len(current_attestations) > 0 and isinstance(current_attestations['validators'].iloc[0], str):\n",
    "        current_attestations['validators'] = current_attestations['validators'].apply(\n",
    "            lambda x: eval(x) if isinstance(x, str) else x\n",
    "        )\n",
    "\n",
    "    print(f\"loaded {len(current_attestations)} attestations from time window {start_date} to {end_date}\")\n",
    "    \n",
    "    all_attestations = pd.concat([all_attestations, current_attestations])\n",
    "\n",
    "print(f\"Loaded {len(all_attestations)} attestations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on the proposer index by fetching the entire block data from the beacon_api_eth_v2_beacon_block table\n",
    "def fetch_proposer_indices(time_ranges, network):\n",
    "    all_proposer_indices = []\n",
    "    for start_date, end_date in time_ranges:\n",
    "        proposer_indices_query = text(\"\"\"\n",
    "            SELECT\n",
    "                slot,\n",
    "                proposer_index\n",
    "            FROM canonical_beacon_block FINAL\n",
    "            WHERE\n",
    "                slot_start_date_time BETWEEN toDateTime(:start_date, 'UTC') AND toDateTime(:end_date, 'UTC')\n",
    "                AND meta_network_name = :network\n",
    "            ORDER BY slot ASC\n",
    "        \"\"\")\n",
    "        proposer_indices = pd.DataFrame(\n",
    "            connection.execute(proposer_indices_query, {\"start_date\": start_date.replace('Z', ''), \"end_date\": end_date.replace('Z', ''), \"network\": network}).fetchall(),\n",
    "            columns=['slot', 'proposer_index']\n",
    "        )\n",
    "        all_proposer_indices.append(proposer_indices)\n",
    "    \n",
    "    return pd.concat(all_proposer_indices, ignore_index=True)\n",
    "\n",
    "proposer_indices = fetch_proposer_indices(config.time_ranges, config.network)\n",
    "\n",
    "# Get the proposer entity from validators map\n",
    "proposer_indices['entity'] = proposer_indices['proposer_index'].apply(\n",
    "    lambda x: get_validator_entity(x, validators)\n",
    ")\n",
    "\n",
    "# Convert proposer_index to int64 to ensure proper matching during merge\n",
    "proposer_indices['proposer_index'] = proposer_indices['proposer_index'].astype('int64')\n",
    "\n",
    "proposer_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Attestation Inclusion\": {\n",
    "        \"description\": (\n",
    "            \"Metrics measuring how effectively attestations are being included in blocks.\\n\"\n",
    "            \"These metrics help evaluate the attestation aggregation changes in the Electra fork.\\n\"\n",
    "            \"They focus on validator participation and timeliness of attestation inclusion.\\n\"\n",
    "        ),\n",
    "        \"metrics\": {\n",
    "            \"unique_validator_indexes\": \"Number of unique validator indexes included in all of the block's attestations.\",\n",
    "            \"unique_committees\": \"Number of unique committees represented in all of the block's attestations.\",\n",
    "            \"first_seen_attestations\": \"Number of validator votes that are included for the first time in the block.\",\n",
    "            \"stale_attestations\": \"Number of attestations that are included in the block but are stale.\",\n",
    "            \"total_attestations\": \"Total number of attestations included in the block.\",\n",
    "            \"optimal_inclusion_validators\": \"Number of validators that were included in the block with a delay of 1 slot.\",\n",
    "            \"optimal_inclusion_rate\": \"Ratio of head timely validators to total unique validators in the block.\",\n",
    "        }\n",
    "    },\n",
    "    \"Attestation Aggregation Efficiency\": {\n",
    "        \"description\": (\n",
    "            \"Metrics evaluating how efficiently attestations are being aggregated.\\n\"\n",
    "            \"These help measure the impact of aggregation changes in the Electra fork.\\n\"\n",
    "            \"Higher aggregation efficiency means more validator votes included with less data overhead.\\n\"\n",
    "        ),\n",
    "        \"metrics\": {\n",
    "            \"avg_validators_per_attestation\": \"Average number of validator indexes per attestation.\",\n",
    "            \"max_validators_per_attestation\": \"Maximum number of validator indexes in any single attestation.\",\n",
    "            \"aggregation_efficiency\": \"Ratio of unique validator attestations to total attestation objects (higher is better).\",\n",
    "        }\n",
    "    },\n",
    "    \"Attestation Inclusion Delay\": {\n",
    "        \"description\": (\n",
    "            \"Metrics focused on the timing aspects of attestation inclusion.\\n\"\n",
    "            \"These metrics help identify how quickly attestations are being included after their target slots.\\n\"\n",
    "            \"Important for understanding network propagation and aggregation speed improvements.\\n\"\n",
    "        ),\n",
    "        \"metrics\": {\n",
    "            \"min_attestation_inclusion_delay\": \"Minimum inclusion delay (in slots) between attestation slot and inclusion slot.\",\n",
    "            \"avg_attestation_inclusion_delay\": \"Average inclusion delay (in slots) between attestation slot and inclusion slot.\",\n",
    "            \"p50_attestation_inclusion_delay\": \"Median inclusion delay (in slots) between attestation slot and inclusion slot.\",\n",
    "            \"p95_attestation_inclusion_delay\": \"95th percentile inclusion delay (in slots) between attestation slot and inclusion slot.\",\n",
    "            \"max_attestation_inclusion_delay\": \"Maximum inclusion delay (in slots) between attestation slot and inclusion slot.\",            \n",
    "        }\n",
    "    },\n",
    "    \"Attestation Inclusion Distribution Per Position\": {\n",
    "        \"description\": {},\n",
    "        \"metrics\": {\n",
    "            \"position_0_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_1_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_2_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_3_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_4_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_5_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_6_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "            \"position_7_average_inclusion_delay\": \"The average inclusion delay of the attestation included in position 0 of the block\",\n",
    "        }\n",
    "    },\n",
    "    \"Attestation Inclusion Delay Counts\": {\n",
    "        \"description\": {},\n",
    "        \"metrics\": {\n",
    "            \"delay_n_count\": \"The count of attestations included in the block with an inclusion delay of n slots\",\n",
    "        }\n",
    "    },\n",
    "    \"Consecutive Missed Slots\": {\n",
    "        \"description\": {},\n",
    "        \"metrics\": {\n",
    "            \"consecutive_missed_slots_1\": \"The count of times where 1 slot in a row was missed\",\n",
    "            \"consecutive_missed_slots_2\": \"The count of times where 2 slots in a row were missed\",\n",
    "            \"consecutive_missed_slots_3\": \"The count of times where 3 slots in a row were missed\",\n",
    "            \"consecutive_missed_slots_4\": \"The count of times where 4 slots in a row were missed\",\n",
    "            \"consecutive_missed_slots_5\": \"The count of times where 5 slots in a row were missed\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_full_metric_description(metric_name):\n",
    "    \"\"\"\n",
    "    Combines the top-level description with the specific metric description.\n",
    "    \n",
    "    Args:\n",
    "        metric_name: The name of the metric to get the description for\n",
    "        \n",
    "    Returns:\n",
    "        A combined description string or None if metric not found\n",
    "    \"\"\"\n",
    "    for category, data in metrics.items():\n",
    "        if metric_name in data[\"metrics\"]:\n",
    "            return f\"{data['description']} {data['metrics'][metric_name]}\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_slot_metrics(group):\n",
    "    \"\"\"Calculates metrics for a single block slot. Does not modify the input group.\"\"\"\n",
    "\n",
    "    if group.empty:\n",
    "        # Return NaNs or appropriate defaults for empty groups\n",
    "        metrics = {\n",
    "            'unique_validator_indexes': 0,\n",
    "            'unique_committees': 0,\n",
    "            'total_attestations': 0,\n",
    "            'optimal_inclusion_validators': 0,\n",
    "            'optimal_inclusion_rate': 0,\n",
    "            'avg_validators_per_attestation': np.nan,\n",
    "            'max_validators_per_attestation': np.nan,\n",
    "            'min_attestation_inclusion_delay': np.nan,\n",
    "            'avg_attestation_inclusion_delay': np.nan,\n",
    "            'p50_attestation_inclusion_delay': np.nan,\n",
    "            'p95_attestation_inclusion_delay': np.nan,\n",
    "            'max_attestation_inclusion_delay': np.nan,\n",
    "            'aggregation_efficiency': np.nan,\n",
    "            'first_seen_attestations': np.nan,\n",
    "            'stale_attestations': 0,\n",
    "            'block_slot_start_date_time': pd.NaT\n",
    "        }\n",
    "        # Add position-specific metrics\n",
    "        for i in range(8):\n",
    "            metrics[f'position_{i}_average_inclusion_delay'] = np.nan\n",
    "        \n",
    "        # Add inclusion delay count metrics\n",
    "        for i in range(1, 33):\n",
    "            metrics[f'delay_{i}_count'] = 0\n",
    "            \n",
    "        return pd.Series(metrics)\n",
    "    # Calculate temporary series needed for metrics\n",
    "    attestation_delay = group['block_slot'] - group['slot']\n",
    "\n",
    "    negative_delays = attestation_delay[attestation_delay < 0]\n",
    "    if not negative_delays.empty:\n",
    "        print(f\"Negative delays found: {negative_delays}\")\n",
    "        exit()\n",
    "\n",
    "    # Explode validators for unique count\n",
    "    validators_list = group['validators'].tolist()\n",
    "    flat_validators = []\n",
    "    \n",
    "    for validator_array in validators_list:\n",
    "        # Check if already a list or needs parsing\n",
    "        if isinstance(validator_array, list):\n",
    "            flat_validators.extend(validator_array)\n",
    "        elif isinstance(validator_array, str) and validator_array.startswith('['):\n",
    "            # Parse string representation\n",
    "            import ast\n",
    "            try:\n",
    "                parsed = ast.literal_eval(validator_array)\n",
    "                if isinstance(parsed, list):\n",
    "                    flat_validators.extend(parsed)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    all_validators_in_slot = np.unique(np.array(flat_validators))\n",
    "    unique_validator_count = len(all_validators_in_slot)\n",
    "\n",
    "    # optimal_inclusion_validators - count unique validators with delay=1\n",
    "    optimal_inclusion_mask = attestation_delay == 1\n",
    "    optimal_inclusion_group = group[optimal_inclusion_mask]\n",
    "    \n",
    "    # Get unique validators from attestations with delay=1\n",
    "    optimal_inclusion_validators_list = []\n",
    "    for validator_array in optimal_inclusion_group['validators'].tolist():\n",
    "        if isinstance(validator_array, list):\n",
    "            optimal_inclusion_validators_list.extend(validator_array)\n",
    "        elif isinstance(validator_array, str) and validator_array.startswith('['):\n",
    "            import ast\n",
    "            try:\n",
    "                parsed = ast.literal_eval(validator_array)\n",
    "                if isinstance(parsed, list):\n",
    "                    optimal_inclusion_validators_list.extend(parsed)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Count unique validators with delay=1\n",
    "    optimal_inclusion_validators = len(np.unique(np.array(optimal_inclusion_validators_list)))\n",
    "    optimal_inclusion_rate = optimal_inclusion_validators / unique_validator_count if unique_validator_count > 0 else 0\n",
    "\n",
    "    num_signatures = group['validators'].apply(len)\n",
    "    total_attestations_count = len(group)\n",
    "\n",
    "    metrics = {\n",
    "        # Attestation Inclusion\n",
    "        'unique_validator_indexes': unique_validator_count,\n",
    "        'unique_committees': group['committee_index'].nunique(),\n",
    "        'total_attestations': total_attestations_count,\n",
    "        'optimal_inclusion_validators': optimal_inclusion_validators,\n",
    "        'optimal_inclusion_rate': optimal_inclusion_rate,\n",
    "        # Attestation Aggregation\n",
    "        'avg_validators_per_attestation': num_signatures.mean(),\n",
    "        'max_validators_per_attestation': num_signatures.max(),\n",
    "\n",
    "        # Attestation Inclusion Delay\n",
    "        'min_attestation_inclusion_delay': attestation_delay.min(),\n",
    "        'avg_attestation_inclusion_delay': attestation_delay.mean(),\n",
    "        'p50_attestation_inclusion_delay': attestation_delay.quantile(0.50),\n",
    "        'p95_attestation_inclusion_delay': attestation_delay.quantile(0.95),\n",
    "        'max_attestation_inclusion_delay': attestation_delay.max(),\n",
    "    }\n",
    "\n",
    "    # Calculate position-specific metrics\n",
    "    for i in range(8):\n",
    "        position_data = group[group['position_in_block'] == i]\n",
    "        if not position_data.empty:\n",
    "            position_delay = position_data['block_slot'] - position_data['slot']\n",
    "            metrics[f'position_{i}_average_inclusion_delay'] = position_delay.mean()\n",
    "        else:\n",
    "            metrics[f'position_{i}_average_inclusion_delay'] = np.nan\n",
    "    \n",
    "    # Calculate inclusion delay counts (up to 32 slots)\n",
    "    delay_counts = attestation_delay.value_counts().sort_index()\n",
    "    for i in range(1, 33):\n",
    "        if i in delay_counts.index:\n",
    "            metrics[f'delay_{i}_count'] = delay_counts[i]\n",
    "        else:\n",
    "            metrics[f'delay_{i}_count'] = 0\n",
    "\n",
    "    # Derived metric\n",
    "    if total_attestations_count > 0:\n",
    "        metrics['aggregation_efficiency'] = unique_validator_count / total_attestations_count\n",
    "    else:\n",
    "        metrics['aggregation_efficiency'] = np.nan # Avoid division by zero\n",
    "\n",
    "    # Add block timestamp for reference (identifying column)\n",
    "    # block_slot is the index of the resulting series/dataframe\n",
    "    metrics['block_slot_start_date_time'] = group['block_slot_start_date_time'].iloc[0]\n",
    "    # Note: block_epoch is not in the original query's selected columns for all_attestations\n",
    "\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Dictionary to track seen attestations: {slot: {validator_index: True}}\n",
    "seen_attestations = {}\n",
    "\n",
    "def calculate_first_seen_attestations(df):\n",
    "    \"\"\"\n",
    "    Process the dataframe to calculate first_seen_attestations for each block.\n",
    "    Maintains a rolling window of 65 slots to track previously seen validator attestations.\n",
    "    \"\"\"\n",
    "    # Sort by block_slot to ensure chronological processing\n",
    "    df = df.sort_values(['block_slot', 'slot']).copy()\n",
    "    \n",
    "    # Add a column to track first seen validators per attestation\n",
    "    df['first_seen_validators'] = 0\n",
    "    df['stale_attestations'] = 0\n",
    "    \n",
    "    # Dictionary to track seen attestations: {slot: {validator_index: True}}\n",
    "    seen_attestations = {}\n",
    "    \n",
    "    # Process each row to identify first seen attestations\n",
    "    for idx, row in df.iterrows():\n",
    "        block_slot = row['block_slot']\n",
    "        attestation_slot = row['slot']\n",
    "        validator_indexes = row['validators']\n",
    "        if isinstance(validator_indexes, str) and validator_indexes.startswith('['):\n",
    "            # Parse string representation\n",
    "            import ast\n",
    "            try:\n",
    "                validator_indexes = ast.literal_eval(validator_indexes)\n",
    "            except:\n",
    "                validator_indexes = []\n",
    "        \n",
    "        # Clean up old slots (keep only last 65 slots)\n",
    "        current_slots = list(seen_attestations.keys())\n",
    "        for slot in current_slots:\n",
    "            if block_slot - slot > 65:\n",
    "                del seen_attestations[slot]\n",
    "        \n",
    "        # Count validators in this attestation not seen before for this slot\n",
    "        first_seen_count = 0\n",
    "        stale_count = 0\n",
    "        for validator_idx in validator_indexes:\n",
    "            if attestation_slot not in seen_attestations or validator_idx not in seen_attestations[attestation_slot]:\n",
    "                first_seen_count += 1\n",
    "                # Initialize the slot dictionary if needed\n",
    "                if attestation_slot not in seen_attestations:\n",
    "                    seen_attestations[attestation_slot] = {}\n",
    "                # Mark this validator as having attested for this slot\n",
    "                seen_attestations[attestation_slot][validator_idx] = True\n",
    "            else:\n",
    "                # This is a stale attestation - we've seen it before\n",
    "                stale_count += 1\n",
    "        \n",
    "        # Store the count of first seen validators for this attestation\n",
    "        df.at[idx, 'first_seen_validators'] = first_seen_count\n",
    "        df.at[idx, 'stale_attestations'] = stale_count\n",
    "    \n",
    "    # Aggregate first seen validators by block_slot\n",
    "    block_first_seen = df.groupby('block_slot')['first_seen_validators'].sum()\n",
    "    block_stale = df.groupby('block_slot')['stale_attestations'].sum()\n",
    "    \n",
    "    return block_first_seen, block_stale\n",
    "\n",
    "def calculate_consecutive_missed_slots(df):\n",
    "    \"\"\"\n",
    "    Calculate metrics for consecutive missed slots for each time range separately.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with block_slot column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with consecutive missed slots metrics\n",
    "    \"\"\"\n",
    "    # Initialize counters for consecutive missed slots\n",
    "    consecutive_missed = {\n",
    "        'consecutive_missed_slots_1': 0,\n",
    "        'consecutive_missed_slots_2': 0,\n",
    "        'consecutive_missed_slots_3': 0,\n",
    "        'consecutive_missed_slots_4': 0,\n",
    "        'consecutive_missed_slots_5': 0,\n",
    "    }\n",
    "    \n",
    "    # Process each time range separately\n",
    "    for start_date, end_date in config.time_ranges:\n",
    "        # Filter data for this time range\n",
    "        time_range_df = df[(df['block_slot_start_date_time'] >= pd.to_datetime(start_date.replace('Z', ''))) & \n",
    "                           (df['block_slot_start_date_time'] <= pd.to_datetime(end_date.replace('Z', '')))]\n",
    "        \n",
    "        if time_range_df.empty:\n",
    "            continue\n",
    "            \n",
    "        # Get min and max slot for this time range\n",
    "        min_slot = time_range_df['block_slot'].min()\n",
    "        max_slot = time_range_df['block_slot'].max()\n",
    "        \n",
    "        # Create a set of all slots that have blocks in this time range\n",
    "        slots_with_blocks = set(time_range_df['block_slot'].unique())\n",
    "        \n",
    "        # Track current streak of missed slots\n",
    "        current_streak = 0\n",
    "        \n",
    "        # Iterate through each slot in the range\n",
    "        for slot in range(min_slot, max_slot + 1):\n",
    "            if slot not in slots_with_blocks:\n",
    "                # This slot was missed\n",
    "                current_streak += 1\n",
    "            else:\n",
    "                # This slot has a block, check if we had a streak before\n",
    "                if 1 <= current_streak <= 5:\n",
    "                    consecutive_missed[f'consecutive_missed_slots_{current_streak}'] += 1\n",
    "                elif current_streak > 5:\n",
    "                    # Count longer streaks in the 5+ category\n",
    "                    consecutive_missed['consecutive_missed_slots_5'] += 1\n",
    "                \n",
    "                # Reset streak counter\n",
    "                current_streak = 0\n",
    "        \n",
    "        # Check if we ended with a streak\n",
    "        if 1 <= current_streak <= 5:\n",
    "            consecutive_missed[f'consecutive_missed_slots_{current_streak}'] += 1\n",
    "        elif current_streak > 5:\n",
    "            consecutive_missed['consecutive_missed_slots_5'] += 1\n",
    "    \n",
    "    return pd.Series(consecutive_missed)\n",
    "\n",
    "# Group by block_slot and apply the metric calculation to create a *new* DataFrame\n",
    "print(\"Calculating metrics per slot...\")\n",
    "# First calculate basic metrics\n",
    "slot_metrics_df = all_attestations.groupby('block_slot').apply(calculate_slot_metrics)\n",
    "\n",
    "# Process attestations to calculate first_seen_attestations\n",
    "print(\"Calculating first seen attestations...\")\n",
    "first_seen_counts, stale_counts = calculate_first_seen_attestations(all_attestations)\n",
    "\n",
    "# Add first_seen_attestations to the metrics dataframe\n",
    "slot_metrics_df['first_seen_attestations'] = first_seen_counts\n",
    "slot_metrics_df['stale_attestations'] = stale_counts\n",
    "\n",
    "# Calculate consecutive missed slots metrics\n",
    "print(\"Calculating consecutive missed slots...\")\n",
    "consecutive_missed_metrics = calculate_consecutive_missed_slots(all_attestations)\n",
    "\n",
    "# Add consecutive missed slots metrics to the dataframe\n",
    "for metric, value in consecutive_missed_metrics.items():\n",
    "    slot_metrics_df[metric] = value\n",
    "\n",
    "print(\"Metrics calculation complete.\")\n",
    "\n",
    "# Add proposer_index to the metrics dataframe\n",
    "slot_metrics_df = slot_metrics_df.reset_index()\n",
    "slot_metrics_df = pd.merge(\n",
    "    slot_metrics_df,\n",
    "    proposer_indices[['slot', 'proposer_index', 'entity']],\n",
    "    left_on='block_slot',\n",
    "    right_on='slot',\n",
    "    how='left'\n",
    ")\n",
    "slot_metrics_df = slot_metrics_df.drop('slot', axis=1).set_index('block_slot')\n",
    "\n",
    "# Display the first few rows of the resulting metrics DataFrame\n",
    "# This DataFrame contains only the block_slot (as index) and the calculated metrics + block_slot_start_date_time\n",
    "print(slot_metrics_df.head())\n",
    "\n",
    "# Display basic info about the new metrics DataFrame\n",
    "print(slot_metrics_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_data(entity_name):\n",
    "    \"\"\"\n",
    "    Prepares and filters data for a specific entity.\n",
    "    \n",
    "    Args:\n",
    "        entity_name (str): The name of the entity to filter by\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Filtered and prepared data for the entity\n",
    "    \"\"\"\n",
    "    if entity_name == \"all\":\n",
    "        entity_data = slot_metrics_df\n",
    "    else:\n",
    "        # Filter for blocks proposed by the specified entity\n",
    "        return slot_metrics_df[slot_metrics_df['proposer_index'].apply(lambda x: is_validator_from_entity(x, entity_name, validators))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_before_after_by_entity(entity_name, metric='aggregation_efficiency', data=slot_metrics_df):\n",
    "    \"\"\"\n",
    "    Creates a before/after comparison plot of attestation metrics for a specific entity.\n",
    "    \n",
    "    Args:\n",
    "        entity_name (str): The name of the entity to filter by\n",
    "        metric (str): The metric to use for comparison (e.g., 'aggregation_efficiency', 'unique_validator_indexes')\n",
    "        data (DataFrame): The dataframe containing attestation metrics\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import matplotlib.dates as mdates\n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    import textwrap\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "    # Copy the data to avoid modifying the original data\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Prepare data\n",
    "    if entity_name == \"all\":\n",
    "        valid_data = data_copy\n",
    "    else:\n",
    "        # Filter data for blocks proposed by the specified entity\n",
    "        valid_data = data_copy[data_copy['entity'] == entity_name].copy()\n",
    "    \n",
    "    if len(valid_data) == 0:\n",
    "        print(f\"No blocks found for entity: {entity_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure the metric exists in the data\n",
    "    if metric not in valid_data.columns:\n",
    "        print(f\"Metric '{metric}' not found in data. Available metrics: {', '.join(valid_data.columns)}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert datetime for plotting\n",
    "    valid_data['timestamp'] = pd.to_datetime(valid_data['block_slot_start_date_time'])\n",
    "    \n",
    "    # Convert event_date to naive datetime if it's timezone-aware\n",
    "    event_date_naive = pd.Timestamp(event_date).tz_localize(None) if hasattr(event_date, 'tzinfo') and event_date.tzinfo is not None else event_date\n",
    "    \n",
    "    # Create before/after groups\n",
    "    valid_data['period'] = np.where(valid_data['timestamp'] < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Create a figure with 2x2 layout with 16:9 aspect ratio\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Create the four plots\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Create boxplot\n",
    "    sns.boxplot(x='period', y=metric, data=valid_data, ax=ax1)\n",
    "    ax1.set_title(f'Distribution of {metric}')\n",
    "    ax1.set_xlabel('Period')\n",
    "    ax1.set_ylabel(metric)\n",
    "    \n",
    "    # Create violinplot with more accurate boundaries\n",
    "    # Find the actual min value to set proper y-axis limits\n",
    "    min_value = valid_data[metric].min()\n",
    "    # Ensure the y-axis starts at the actual minimum (or 0 if all values are positive)\n",
    "    y_min = max(0, min_value) if min_value > 0 else min_value\n",
    "    \n",
    "    sns.violinplot(x='period', y=metric, data=valid_data, ax=ax2, cut=0)  # cut=0 prevents extending beyond observed data\n",
    "    ax2.set_title(f'Density Distribution of {metric}')\n",
    "    ax2.set_xlabel('Period')\n",
    "    ax2.set_ylabel(metric)\n",
    "    ax2.set_ylim(bottom=y_min)  # Set the bottom limit to actual minimum or 0\n",
    "    \n",
    "    # Create histogram\n",
    "    bins = np.linspace(valid_data[metric].min(), valid_data[metric].max(), 15)\n",
    "    ax3.hist(valid_data[valid_data['period'] == 'Before'][metric], bins=bins, alpha=0.5, label='Before')\n",
    "    ax3.hist(valid_data[valid_data['period'] == 'After'][metric], bins=bins, alpha=0.5, label='After')\n",
    "    ax3.set_title(f'Histogram of {metric}')\n",
    "    ax3.set_xlabel(metric)\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Create ECDF plot\n",
    "    for period in ['Before', 'After']:\n",
    "        period_data = valid_data[valid_data['period'] == period][metric].sort_values()\n",
    "        ecdf = np.arange(1, len(period_data) + 1) / len(period_data)\n",
    "        ax4.plot(period_data, ecdf, label=period)\n",
    "    ax4.set_title(f'Empirical CDF of {metric}')\n",
    "    ax4.set_xlabel(metric)\n",
    "    ax4.set_ylabel('ECDF')\n",
    "    ax4.legend()\n",
    "    \n",
    "    # Find the metric description\n",
    "    metric_description = None\n",
    "    category_description = None\n",
    "    metric_category = None\n",
    "    \n",
    "    for category, data in metrics.items():\n",
    "        if metric in data[\"metrics\"]:\n",
    "            metric_category = category\n",
    "            category_description = data['description']\n",
    "            metric_description = data['metrics'][metric]\n",
    "            break\n",
    "    if metric.startswith(\"delay_\"):\n",
    "        metric_description = f\"Number of attestations included in the block with an inclusion delay of {metric.split('_')[1]} slots.\"\n",
    "    # Add date range information\n",
    "    data_ranges_text = \"Time ranges used for analysis:\\n\"\n",
    "    for start_date, end_date in config.time_ranges:\n",
    "        days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\n",
    "        data_ranges_text += f\"{start_date} to {end_date} ({days} days)\\n\"\n",
    "    fig.text(0.98, 0.01, data_ranges_text, fontsize=10, style='italic', ha='right')\n",
    "\n",
    "    # Add the number of blocks analyzed before and after and network name\n",
    "    before_count = len(valid_data[valid_data['period'] == 'Before'])\n",
    "    after_count = len(valid_data[valid_data['period'] == 'After'])\n",
    "    fig.text(0.02, 0.01, f'Blocks analyzed: Before={before_count}, After={after_count}\\nNetwork: {config.network}\\nBefore/After Event Date: {event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\")}', fontsize=10, style='italic')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    add_branding(fig, title=f\"{metric_category if metric_category else 'Attestation Metrics'} for blocks proposed by {entity_name}\", \n",
    "                subtitle=f\"{metric_description if metric_description else metric}\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through all metrics defined in the metrics dictionary for each entity\n",
    "entities = [\n",
    "    \"all\",\n",
    "    # \"teku\",\n",
    "    # \"lighthouse\",\n",
    "    # \"prysm\"\n",
    "    ]\n",
    "\n",
    "for entity in entities:\n",
    "    for category, category_data in metrics.items():\n",
    "        if isinstance(category_data, dict) and \"metrics\" in category_data:\n",
    "            for metric in category_data[\"metrics\"]:\n",
    "                print(f\"Plotting {metric} for {entity}\")\n",
    "                if metric in slot_metrics_df.columns:\n",
    "                    plot_performance_before_after_by_entity(entity, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_before_after_by_entity(\"nimbus\", metric=\"delay_1_count\").show()\n",
    "plot_performance_before_after_by_entity(\"all\", metric=\"delay_1_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_before_after_by_entity(\"all\", metric=\"first_seen_attestations\").show()\n",
    "plot_performance_before_after_by_entity(\"nimbus\", metric=\"optimal_inclusion_validators\").show()\n",
    "plot_performance_before_after_by_entity(\"grandine\", metric=\"optimal_inclusion_validators\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a distribution chart of consecutive missed slots before and after the event\n",
    "def plot_missed_slots_distribution():\n",
    "    # Extract the consecutive missed slots metrics\n",
    "    missed_slots_metrics = [col for col in slot_metrics_df.columns if col.startswith('consecutive_missed_slots_')]\n",
    "    \n",
    "    # Create a dataframe with the counts\n",
    "    missed_slots_counts = slot_metrics_df[missed_slots_metrics].iloc[0]\n",
    "    \n",
    "    # Extract the numbers from the column names for x-axis labels\n",
    "    x_labels = [f\"{col.split('_')[-1]}\" for col in missed_slots_metrics]\n",
    "    x_labels = [label if label != '5' else '5+' for label in x_labels]\n",
    "    \n",
    "    # Split data into before and after\n",
    "    slot_metrics_df['datetime'] = pd.to_datetime(slot_metrics_df['block_slot_start_date_time'])\n",
    "    before_df = slot_metrics_df[slot_metrics_df['datetime'] < event_date_naive]\n",
    "    after_df = slot_metrics_df[slot_metrics_df['datetime'] >= event_date_naive]\n",
    "    \n",
    "    # Calculate missed slots for before and after periods\n",
    "    before_missed_slots = calculate_consecutive_missed_slots(all_attestations[all_attestations['block_slot_start_date_time'] < event_date_naive])\n",
    "    after_missed_slots = calculate_consecutive_missed_slots(all_attestations[all_attestations['block_slot_start_date_time'] >= event_date_naive])\n",
    "    \n",
    "    # Create the figure\n",
    "    fig, ax = plt.subplots(figsize=(13, 5))\n",
    "    \n",
    "    # Width of bars\n",
    "    width = 0.35\n",
    "    \n",
    "    # X positions for bars\n",
    "    x = np.arange(len(x_labels))\n",
    "    \n",
    "    # Plot the bar charts\n",
    "    bars1 = ax.bar(x - width/2, before_missed_slots.values, width, label='Before', color='steelblue')\n",
    "    bars2 = ax.bar(x + width/2, after_missed_slots.values, width, label='After', color='darkorange')\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Number of Consecutive Missed Slots', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    # Add grid for better readability\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add date range information\n",
    "    data_ranges_text = \"Time ranges used for analysis:\\n\"\n",
    "    for start_date, end_date in config.time_ranges:\n",
    "        days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\n",
    "        data_ranges_text += f\"{start_date} to {end_date} ({days} days)\\n\"\n",
    "    fig.text(0.98, 0.01, data_ranges_text, fontsize=10, style='italic', ha='right')\n",
    "    \n",
    "    # Add network information\n",
    "    fig.text(0.02, 0.01, f'Network: {config.network}\\nBefore/After Event Date: {event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\")}', fontsize=10, style='italic')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    add_branding(fig, title=\"Distribution of Consecutive Missed Slots\", \n",
    "                subtitle=\"Frequency of different lengths of consecutive missed slots before and after event\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Plot the missed slots distribution\n",
    "plot_missed_slots_distribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart of occurrences where entities have values below/above a threshold before and after the event\n",
    "def plot_metric_by_entity(df, metric, threshold=None, comparison='less', title_prefix=\"Number of Blocks with\"):\n",
    "    # Make a copy of the dataframe\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    # Filter based on the comparison type and threshold if provided\n",
    "    if threshold is not None:\n",
    "        if comparison == 'less':\n",
    "            filtered_df = filtered_df[filtered_df[metric] < threshold]\n",
    "            comparison_text = f\"< {threshold}\"\n",
    "        elif comparison == 'greater':\n",
    "            filtered_df = filtered_df[filtered_df[metric] > threshold]\n",
    "            comparison_text = f\"> {threshold}\"\n",
    "        elif comparison == 'equal':\n",
    "            filtered_df = filtered_df[filtered_df[metric] == threshold]\n",
    "            comparison_text = f\"= {threshold}\"\n",
    "    else:\n",
    "        comparison_text = \"\"\n",
    "    \n",
    "    # Convert index to datetime if it's not already\n",
    "    if not isinstance(filtered_df.index, pd.DatetimeIndex):\n",
    "        filtered_df['datetime_index'] = pd.to_datetime(filtered_df['block_slot_start_date_time'])\n",
    "        # Add period information based on event_date\n",
    "        filtered_df['period'] = np.where(filtered_df['datetime_index'] < event_date_naive, 'Before', 'After')\n",
    "    else:\n",
    "        # Add period information based on event_date\n",
    "        filtered_df['period'] = np.where(filtered_df.index < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Count occurrences by entity and period\n",
    "    entity_period_counts = filtered_df.groupby(['entity', 'period']).size().reset_index()\n",
    "    entity_period_counts.columns = ['entity', 'period', 'count']\n",
    "    \n",
    "    # Pivot to get before/after as separate columns\n",
    "    pivot_df = entity_period_counts.pivot(index='entity', columns='period', values='count').fillna(0)\n",
    "    \n",
    "    # Ensure both Before and After columns exist\n",
    "    if 'Before' not in pivot_df.columns:\n",
    "        pivot_df['Before'] = 0\n",
    "    if 'After' not in pivot_df.columns:\n",
    "        pivot_df['After'] = 0\n",
    "    \n",
    "    # Sort by total count (Before + After) in descending order\n",
    "    pivot_df['Total'] = pivot_df['Before'] + pivot_df['After']\n",
    "    pivot_df = pivot_df.sort_values('Total', ascending=False).drop('Total', axis=1)\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(pivot_df.index))\n",
    "    \n",
    "    # Create bars\n",
    "    before_bars = ax.bar(x - bar_width/2, pivot_df['Before'], bar_width, label='Before')\n",
    "    after_bars = ax.bar(x + bar_width/2, pivot_df['After'], bar_width, label='After')\n",
    "    \n",
    "    # Add count labels on top of each bar\n",
    "    for bars in [before_bars, after_bars]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                        f'{height:.0f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Add labels and title\n",
    "    title = f'{title_prefix} {comparison_text} {metric} by Entity (Before vs After)'\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Entity')\n",
    "    ax.set_ylabel('Number of Blocks')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(pivot_df.index, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    # For calculating stats, use the same datetime comparison approach\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        temp_df = df.copy()\n",
    "        temp_df['datetime_index'] = pd.to_datetime(temp_df['block_slot_start_date_time'])\n",
    "        before_total = len(temp_df[temp_df['datetime_index'] < event_date_naive])\n",
    "        after_total = len(temp_df[temp_df['datetime_index'] >= event_date_naive])\n",
    "    else:\n",
    "        before_total = len(df[df.index < event_date_naive])\n",
    "        after_total = len(df[df.index >= event_date_naive])\n",
    "    \n",
    "    before_filtered = len(filtered_df[filtered_df['period'] == 'Before'])\n",
    "    after_filtered = len(filtered_df[filtered_df['period'] == 'After'])\n",
    "    \n",
    "    before_pct = (before_filtered / before_total) * 100 if before_total > 0 else 0\n",
    "    after_pct = (after_filtered / after_total) * 100 if after_total > 0 else 0\n",
    "    \n",
    "    plt.figtext(0.02, 0.02, \n",
    "                f'Before event: {before_filtered}/{before_total} blocks ({before_pct:.2f}%)\\n'\n",
    "                f'After event: {after_filtered}/{after_total} blocks ({after_pct:.2f}%)',\n",
    "                fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Example usage for first_seen_attestations\n",
    "plot_metric_by_entity(slot_metrics_df, 'first_seen_attestations', threshold=10000, comparison='less')\n",
    "\n",
    "# Example usage for optimal_inclusion_rate\n",
    "plot_metric_by_entity(slot_metrics_df, 'optimal_inclusion_rate', threshold=0.9, comparison='less')\n",
    "\n",
    "plot_metric_by_entity(slot_metrics_df, 'optimal_inclusion_validators', threshold=25000, comparison='less')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entity_metrics_before_after(df, metric, aggregation='mean', title_prefix=\"Comparison of\", figsize=(13, 6), entities=None):\n",
    "    \"\"\"\n",
    "    Compare a metric before and after the event for each entity with optional aggregation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The dataframe containing the data\n",
    "    metric : str\n",
    "        The column name of the metric to analyze\n",
    "    aggregation : str, default 'mean'\n",
    "        The aggregation function to apply ('mean', 'median', 'sum', 'max', 'min', 'count')\n",
    "    title_prefix : str, default \"Comparison of\"\n",
    "        Prefix for the plot title\n",
    "    figsize : tuple, default (12, 10)\n",
    "        Figure size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.pyplot object\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    temp_df = df.copy()\n",
    "\n",
    "    if entities is None:\n",
    "        entities = temp_df['entity'].unique()\n",
    "    elif \"all\" in entities:\n",
    "        # Add \"all\" as an entity for comparison\n",
    "        all_df = temp_df.copy()\n",
    "        all_df['entity'] = 'all'\n",
    "        temp_df = pd.concat([temp_df, all_df])\n",
    "        entities = [e for e in entities if e != \"all\"] + [\"all\"]\n",
    "\n",
    "    # Filter the dataframe to only include the specified entities\n",
    "    temp_df = temp_df[temp_df['entity'].isin(entities)]\n",
    "    \n",
    "    # Ensure datetime column exists and add period information based on event_date\n",
    "    if not isinstance(temp_df.index, pd.DatetimeIndex):\n",
    "        temp_df['datetime_index'] = pd.to_datetime(temp_df['block_slot_start_date_time'])\n",
    "        temp_df['period'] = np.where(temp_df['datetime_index'] < event_date_naive, 'Before', 'After')\n",
    "    else:\n",
    "        temp_df['period'] = np.where(temp_df.index < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Apply aggregation by entity and period\n",
    "    agg_func = getattr(np, aggregation)\n",
    "    entity_metrics = temp_df.groupby(['entity', 'period'])[metric].agg(agg_func).reset_index()\n",
    "    \n",
    "    # Pivot to get before/after as separate columns\n",
    "    pivot_df = entity_metrics.pivot(index='entity', columns='period', values=metric).fillna(0)\n",
    "    \n",
    "    # Ensure both Before and After columns exist\n",
    "    if 'Before' not in pivot_df.columns:\n",
    "        pivot_df['Before'] = 0\n",
    "    if 'After' not in pivot_df.columns:\n",
    "        pivot_df['After'] = 0\n",
    "    \n",
    "    # Calculate percent change\n",
    "    pivot_df['% Change'] = (pivot_df['After'] - pivot_df['Before']) / pivot_df['Before'] * 100\n",
    "    \n",
    "    # Sort by absolute percent change\n",
    "    pivot_df = pivot_df.sort_values(by='% Change', ascending=False)\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(pivot_df.index))\n",
    "    \n",
    "    # Create bars\n",
    "    before_bars = ax.bar(x - bar_width/2, pivot_df['Before'], bar_width, label='Before')\n",
    "    after_bars = ax.bar(x + bar_width/2, pivot_df['After'], bar_width, label='After')\n",
    "    \n",
    "    # Add labels and title\n",
    "    title = f'{title_prefix} {metric} ({aggregation}) by Entity'\n",
    "    # ax.set_title(title)\n",
    "    ax.set_xlabel('Entity')\n",
    "    ax.set_ylabel(f'{aggregation.capitalize()} of {metric}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(pivot_df.index, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add a table with the percent changes\n",
    "    table_data = []\n",
    "    for entity in pivot_df.index:\n",
    "        before = pivot_df.loc[entity, 'Before']\n",
    "        after = pivot_df.loc[entity, 'After']\n",
    "        pct_change = pivot_df.loc[entity, '% Change']\n",
    "        table_data.append([entity, f\"{before:.2f}\", f\"{after:.2f}\", f\"{pct_change:.2f}%\"])\n",
    "    \n",
    "    # For calculating stats, use the same datetime comparison approach as in plot_metric_by_entity\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        count_df = df.copy()\n",
    "        count_df['datetime_index'] = pd.to_datetime(count_df['block_slot_start_date_time'])\n",
    "        before_count = len(count_df[count_df['datetime_index'] < event_date_naive])\n",
    "        after_count = len(count_df[count_df['datetime_index'] >= event_date_naive])\n",
    "    else:\n",
    "        before_count = len(df[df.index < event_date_naive])\n",
    "        after_count = len(df[df.index >= event_date_naive])\n",
    "    \n",
    "    # Add summary stats as text\n",
    "    before_avg = pivot_df['Before'].mean()\n",
    "    after_avg = pivot_df['After'].mean()\n",
    "    overall_pct_change = ((after_avg - before_avg) / before_avg * 100) if before_avg > 0 else float('inf')\n",
    "    \n",
    "    plt.figtext(0.02, 0.90, \n",
    "                f'Overall {aggregation} before: {before_avg:.2f} ({before_count} blocks)\\n'\n",
    "                f'Overall {aggregation} after: {after_avg:.2f} ({after_count} blocks)\\n'\n",
    "                f'Overall % change: {overall_pct_change:.2f}%',\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Add date range information\n",
    "    data_ranges_text = \"Time ranges used for analysis:\\n\"\n",
    "    for start_date, end_date in config.time_ranges:\n",
    "        days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\n",
    "        data_ranges_text += f\"- {start_date} to {end_date} ({days} days)\\n\"\n",
    "    fig.text(0.98, 0.90, data_ranges_text, fontsize=10, style='italic', ha='right')\n",
    "\n",
    "    add_branding(fig, title, subtitle=\"Before/After: \" + event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\") + \" on \" + config.network\n",
    "                 , title_size=16, subtitle_size=12)\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "client_teams = [\n",
    "    \"all\",\n",
    "    \"prysm\",\n",
    "    \"lighthouse\",\n",
    "    \"teku\",\n",
    "    \"nimbus\",\n",
    "    \"lodestar\",\n",
    "    \"grandine\",\n",
    "    \"ethpandaops\"\n",
    "]\n",
    "\n",
    "# Example usage\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'optimal_inclusion_rate', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'first_seen_attestations', aggregation='median', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'first_seen_attestations', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'optimal_inclusion_validators', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'optimal_inclusion_validators', aggregation='median', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'min_attestation_inclusion_delay', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'min_attestation_inclusion_delay', aggregation='max', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'min_attestation_inclusion_delay', aggregation='mean', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'avg_attestation_inclusion_delay', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'p50_attestation_inclusion_delay', aggregation='average', entities=client_teams)\n",
    "compare_entity_metrics_before_after(slot_metrics_df, 'p95_attestation_inclusion_delay', aggregation='mean', entities=client_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot position-specific metrics for each entity\n",
    "def plot_position_metrics_by_entity(df, entities=None, figsize=(18, 15)):\n",
    "    \"\"\"\n",
    "    Plot the average inclusion delay for each position in block by entity, comparing before and after.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The dataframe containing the metrics data\n",
    "    entities : list, optional\n",
    "        List of entities to include in the plot\n",
    "    figsize : tuple, default (18, 15)\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    if entities is None:\n",
    "        entities = temp_df['entity'].unique()\n",
    "    elif \"all\" in entities:\n",
    "        # Add \"all\" as an entity for comparison\n",
    "        all_df = temp_df.copy()\n",
    "        all_df['entity'] = 'all'\n",
    "        temp_df = pd.concat([temp_df, all_df])\n",
    "        entities = [e for e in entities if e != \"all\"] + [\"all\"]\n",
    "    \n",
    "    # Filter the dataframe to only include the specified entities\n",
    "    temp_df = temp_df[temp_df['entity'].isin(entities)]\n",
    "    \n",
    "    # Add period information based on event_date\n",
    "    if not isinstance(temp_df.index, pd.DatetimeIndex):\n",
    "        temp_df['datetime_index'] = pd.to_datetime(temp_df['block_slot_start_date_time'])\n",
    "        temp_df['period'] = np.where(temp_df['datetime_index'] < event_date_naive, 'Before', 'After')\n",
    "    else:\n",
    "        temp_df['period'] = np.where(temp_df.index < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Create a figure with subplots for each position\n",
    "    fig, axes = plt.subplots(2, 4, figsize=figsize, sharex=False, sharey=False)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Colors for before and after\n",
    "    colors = {'Before': 'blue', 'After': 'orange'}\n",
    "    \n",
    "    # Calculate overall percent change across all positions to determine consistent sorting\n",
    "    overall_changes = {}\n",
    "    for entity in entities:\n",
    "        entity_data = temp_df[temp_df['entity'] == entity]\n",
    "        before_avg = entity_data[entity_data['period'] == 'Before'][[f'position_{pos}_average_inclusion_delay' for pos in range(8)]].mean().mean()\n",
    "        after_avg = entity_data[entity_data['period'] == 'After'][[f'position_{pos}_average_inclusion_delay' for pos in range(8)]].mean().mean()\n",
    "        if before_avg > 0:\n",
    "            overall_changes[entity] = (after_avg - before_avg) / before_avg * 100\n",
    "        else:\n",
    "            overall_changes[entity] = 0\n",
    "    \n",
    "    # Sort entities by overall percent change\n",
    "    sorted_entities = sorted(overall_changes.keys(), key=lambda x: overall_changes[x], reverse=True)\n",
    "    \n",
    "    # For each position, create a grouped bar chart\n",
    "    for pos in range(8):\n",
    "        position_col = f'position_{pos}_average_inclusion_delay'\n",
    "        \n",
    "        # Calculate mean for each entity and period\n",
    "        position_data = temp_df.groupby(['entity', 'period'])[position_col].mean().reset_index()\n",
    "        \n",
    "        # Pivot to get before/after as separate columns\n",
    "        pivot_df = position_data.pivot(index='entity', columns='period', values=position_col).fillna(0)\n",
    "        \n",
    "        # Ensure both Before and After columns exist\n",
    "        if 'Before' not in pivot_df.columns:\n",
    "            pivot_df['Before'] = 0\n",
    "        if 'After' not in pivot_df.columns:\n",
    "            pivot_df['After'] = 0\n",
    "        \n",
    "        # Calculate percent change\n",
    "        pivot_df['% Change'] = (pivot_df['After'] - pivot_df['Before']) / pivot_df['Before'] * 100\n",
    "        \n",
    "        # Reindex using the consistent entity order\n",
    "        pivot_df = pivot_df.reindex(sorted_entities)\n",
    "        \n",
    "        # Set width of bars\n",
    "        bar_width = 0.35\n",
    "        x = np.arange(len(pivot_df.index))\n",
    "        \n",
    "        # Create bars\n",
    "        axes[pos].bar(x - bar_width/2, pivot_df['Before'], bar_width, label='Before', color=colors['Before'])\n",
    "        axes[pos].bar(x + bar_width/2, pivot_df['After'], bar_width, label='After', color=colors['After'])\n",
    "        \n",
    "        # Add labels\n",
    "        axes[pos].set_title(f'Position {pos}')\n",
    "        axes[pos].set_xticks(x)\n",
    "        axes[pos].set_xticklabels(pivot_df.index, rotation=45, ha='right')\n",
    "        \n",
    "        # Add percent change as text above bars\n",
    "        for i, entity in enumerate(pivot_df.index):\n",
    "            pct_change = pivot_df.loc[entity, '% Change']\n",
    "            axes[pos].text(i, max(pivot_df.loc[entity, 'Before'], pivot_df.loc[entity, 'After']) + 0.1, \n",
    "                          f\"{pct_change:.1f}%\", ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Calculate overall stats for summary\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        count_df = df.copy()\n",
    "        count_df['datetime_index'] = pd.to_datetime(count_df['block_slot_start_date_time'])\n",
    "        before_count = len(count_df[count_df['datetime_index'] < event_date_naive])\n",
    "        after_count = len(count_df[count_df['datetime_index'] >= event_date_naive])\n",
    "    else:\n",
    "        before_count = len(df[df.index < event_date_naive])\n",
    "        after_count = len(df[df.index >= event_date_naive])\n",
    "    \n",
    "    # Add overall title\n",
    "    title = \"Average Attestation Inclusion Delay by Position in Block\"\n",
    "    add_branding(\n",
    "        fig, title, subtitle=\"Before/After: \" + event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\") + \" on \" + config.network\n",
    "        , title_size=16, subtitle_size=12)\n",
    "    \n",
    "    # Add a common legend\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=2)\n",
    "    \n",
    "    # Maximize the use of available space\n",
    "    plt.tight_layout(rect=[0.01, 0.07, 0.99, 0.93])\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "    return plt\n",
    "\n",
    "# Plot position metrics for client teams\n",
    "plot_position_metrics_by_entity(slot_metrics_df, entities=client_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entity_metrics_before_after_with_exclusions(df, metric, aggregation='mean', title_suffix=\"\", figsize=(13, 6), include_entities=None, exclude_entities=None):\n",
    "    \"\"\"\n",
    "    Compare a metric before and after the event for each entity with optional aggregation and exclusions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The dataframe containing the data\n",
    "    metric : str\n",
    "        The column name of the metric to analyze\n",
    "    aggregation : str, default 'mean'\n",
    "        The aggregation function to apply ('mean', 'median', 'sum', 'max', 'min', 'count')\n",
    "    title_prefix : str, default \"Comparison of\"\n",
    "        Prefix for the plot title\n",
    "    figsize : tuple, default (13, 6)\n",
    "        Figure size\n",
    "    include_entities : list, default None\n",
    "        List of entities to include. If \"all\" is in the list, it will add an aggregate of all entities\n",
    "    exclude_entities : list, default None\n",
    "        List of entities to exclude from the \"all\" calculation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.pyplot object\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    # Handle entity filtering\n",
    "    if include_entities is None:\n",
    "        include_entities = temp_df['entity'].unique()\n",
    "    \n",
    "    if exclude_entities is None:\n",
    "        exclude_entities = []\n",
    "    \n",
    "    # Filter the dataframe to only include the specified entities\n",
    "    filtered_entities = [e for e in include_entities if e != \"all\"]\n",
    "    temp_df = temp_df[temp_df['entity'].isin(filtered_entities)]\n",
    "    \n",
    "    # Create the \"all\" entity if requested\n",
    "    if \"all\" in include_entities:\n",
    "        # Create a copy for the \"all\" calculation, excluding specified entities\n",
    "        all_df = df.copy()\n",
    "        if exclude_entities:\n",
    "            all_df = all_df[~all_df['entity'].isin(exclude_entities)]\n",
    "        \n",
    "        all_df['entity'] = 'all'\n",
    "        temp_df = pd.concat([temp_df, all_df])\n",
    "        \n",
    "        # Add excluded entities to the title for clarity\n",
    "        if exclude_entities:\n",
    "            title_suffix += f\"(excluding {', '.join(exclude_entities)})\"\n",
    "    \n",
    "    # Ensure datetime column exists and add period information based on event_date\n",
    "    if not isinstance(temp_df.index, pd.DatetimeIndex):\n",
    "        temp_df['datetime_index'] = pd.to_datetime(temp_df['block_slot_start_date_time'])\n",
    "        temp_df['period'] = np.where(temp_df['datetime_index'] < event_date_naive, 'Before', 'After')\n",
    "    else:\n",
    "        temp_df['period'] = np.where(temp_df.index < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Apply aggregation by entity and period\n",
    "    agg_func = getattr(np, aggregation)\n",
    "    entity_metrics = temp_df.groupby(['entity', 'period'])[metric].agg(agg_func).reset_index()\n",
    "    \n",
    "    # Pivot to get before/after as separate columns\n",
    "    pivot_df = entity_metrics.pivot(index='entity', columns='period', values=metric).fillna(0)\n",
    "    \n",
    "    # Ensure both Before and After columns exist\n",
    "    if 'Before' not in pivot_df.columns:\n",
    "        pivot_df['Before'] = 0\n",
    "    if 'After' not in pivot_df.columns:\n",
    "        pivot_df['After'] = 0\n",
    "    \n",
    "    # Calculate percent change\n",
    "    pivot_df['% Change'] = (pivot_df['After'] - pivot_df['Before']) / pivot_df['Before'] * 100\n",
    "    \n",
    "    # Sort by absolute percent change\n",
    "    pivot_df = pivot_df.sort_values(by='% Change', ascending=False)\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Set width of bars\n",
    "    bar_width = 0.35\n",
    "    x = np.arange(len(pivot_df.index))\n",
    "    \n",
    "    # Create bars\n",
    "    before_bars = ax.bar(x - bar_width/2, pivot_df['Before'], bar_width, label='Before')\n",
    "    after_bars = ax.bar(x + bar_width/2, pivot_df['After'], bar_width, label='After')\n",
    "    \n",
    "    # Add labels and title\n",
    "    title = f'{metric} ({aggregation}) by Entity {title_suffix}'\n",
    "    ax.set_xlabel('Entity')\n",
    "    ax.set_ylabel(f'{aggregation.capitalize()} of {metric}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(pivot_df.index, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    # For calculating stats, use the same datetime comparison approach as in plot_metric_by_entity\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        count_df = df.copy()\n",
    "        count_df['datetime_index'] = pd.to_datetime(count_df['block_slot_start_date_time'])\n",
    "        before_count = len(count_df[count_df['datetime_index'] < event_date_naive])\n",
    "        after_count = len(count_df[count_df['datetime_index'] >= event_date_naive])\n",
    "    else:\n",
    "        before_count = len(df[df.index < event_date_naive])\n",
    "        after_count = len(df[df.index >= event_date_naive])\n",
    "    \n",
    "    # Add summary stats as text\n",
    "    before_avg = pivot_df['Before'].mean()\n",
    "    after_avg = pivot_df['After'].mean()\n",
    "    overall_pct_change = ((after_avg - before_avg) / before_avg * 100) if before_avg > 0 else float('inf')\n",
    "    \n",
    "    plt.figtext(0.02, 0.90, \n",
    "                f'Overall {aggregation} before: {before_avg:.2f} ({before_count} blocks)\\n'\n",
    "                f'Overall {aggregation} after: {after_avg:.2f} ({after_count} blocks)\\n'\n",
    "                f'Overall % change: {overall_pct_change:.2f}%',\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Add date range information\n",
    "    data_ranges_text = \"Time ranges used for analysis:\\n\"\n",
    "    for start_date, end_date in config.time_ranges:\n",
    "        days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\n",
    "        data_ranges_text += f\"- {start_date} to {end_date} ({days} days)\\n\"\n",
    "    fig.text(0.98, 0.90, data_ranges_text, fontsize=10, style='italic', ha='right')\n",
    "\n",
    "    add_branding(fig, title, subtitle=\"Before/After: \" + event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\") + \" on \" + config.network\n",
    "                 , title_size=16, subtitle_size=12)\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Example usage - compare all clients except nimbus\n",
    "compare_entity_metrics_before_after_with_exclusions(\n",
    "    slot_metrics_df, \n",
    "    'optimal_inclusion_validators', \n",
    "    aggregation='average', \n",
    "    include_entities=[\"all\"],\n",
    "    exclude_entities=[\"nimbus\"]\n",
    ")\n",
    "compare_entity_metrics_before_after_with_exclusions(\n",
    "    slot_metrics_df, \n",
    "    'first_seen_attestations', \n",
    "    aggregation='mean', \n",
    "    include_entities=[\"all\"],\n",
    "    exclude_entities=[\"nimbus\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot the distribution of inclusion delay before and after the fork\n",
    "def plot_inclusion_delay_distribution(df, figsize=(8, 4), max_delay=16):\n",
    "    \"\"\"\n",
    "    Plot the distribution of attestation inclusion delay before and after the fork.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The dataframe containing the slot metrics\n",
    "    figsize : tuple, default (16, 10.2)\n",
    "        Figure size\n",
    "    max_delay : int, default 16\n",
    "        Maximum inclusion delay to show in the plot\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    # Ensure datetime column exists and add period information based on event_date\n",
    "    temp_df['datetime'] = pd.to_datetime(temp_df['block_slot_start_date_time'])\n",
    "    temp_df['period'] = np.where(temp_df['datetime'] < event_date_naive, 'Before', 'After')\n",
    "    \n",
    "    # Create a new dataframe to hold the delay counts\n",
    "    delay_data = []\n",
    "    \n",
    "    # Extract delay counts from the delay_n_count columns\n",
    "    for delay in range(1, max_delay + 1):\n",
    "        if f'delay_{delay}_count' in temp_df.columns:\n",
    "            before_count = temp_df[temp_df['period'] == 'Before'][f'delay_{delay}_count'].sum()\n",
    "            after_count = temp_df[temp_df['period'] == 'After'][f'delay_{delay}_count'].sum()\n",
    "            delay_data.append({'inclusion_delay': delay, 'Before': before_count, 'After': after_count})\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    delay_df = pd.DataFrame(delay_data)\n",
    "    delay_df = delay_df.set_index('inclusion_delay')\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    # Plot both before and after on the same plot\n",
    "    width = 0.4\n",
    "    x = np.array(range(1, max_delay + 1))\n",
    "    \n",
    "    before_counts = delay_df['Before'] if 'Before' in delay_df.columns else pd.Series(0, index=x)\n",
    "    after_counts = delay_df['After'] if 'After' in delay_df.columns else pd.Series(0, index=x)\n",
    "    \n",
    "    ax.bar(x - width/2, before_counts.values, width, color='blue', edgecolor='black', label='Before Fork')\n",
    "    ax.bar(x + width/2, after_counts.values, width, color='orange', edgecolor='black', label='After Fork')\n",
    "    \n",
    "    ax.set_xlabel('Inclusion Delay (slots)', fontsize=12)\n",
    "    ax.set_ylabel('Attestation Count', fontsize=12)\n",
    "    ax.set_xlim(0.5, max_delay + 0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "    \n",
    "    # Add date range information\n",
    "    # data_ranges_text = \"Time ranges used for analysis:\\n\"\n",
    "    # for start_date, end_date in config.time_ranges:\n",
    "    #     days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days\n",
    "    #     data_ranges_text += f\"- {start_date} to {end_date} ({days} days)\\n\"\n",
    "    # fig.text(0.98, 0.02, data_ranges_text, fontsize=10, style='italic', ha='right', \n",
    "    #          bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add title and branding\n",
    "    title = f\"Attestation Inclusion Delay Distribution Before vs After Fork\"\n",
    "    add_branding(fig, title, subtitle=\"Before/After: \" + event_date.strftime(\"%Y-%m-%dT%H:%M:%S%z\") + \" on \" + config.network, title_size=9, subtitle_size=8)\n",
    "    \n",
    "    # Reduce padding around the figure\n",
    "    # plt.tight_layout(rect=[0.01, 0.01, 0.99, 0.99])\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Plot the inclusion delay distribution\n",
    "plot_inclusion_delay_distribution(slot_metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

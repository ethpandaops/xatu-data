{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prysm RLNC Block Arrivals Analysis\n",
    "\n",
    "This notebook analyzes the impact of Reed-Solomon Linear Network Coding (RLNC) implementation by Prysm on beacon block propagation times. We compare block arrival times between NFT-Devnet-2 (before RLNC) and NFT-Devnet-3 (after RLNC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samcm/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('./scripts')\n",
    "\n",
    "# Import custom modules\n",
    "from bootstrap import load_env, create_db_url, add_branding, process_config\n",
    "from clickhouse import ClickhouseClient\n",
    "from transforms import process_block_data, process_blob_data, calculate_arrival_metrics, compare_networks\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    \"before\": {\n",
    "        \"network\": \"nft-devnet-2\",\n",
    "        \"start_at_slot\": 0,\n",
    "        \"finish_at_slot\": 2000\n",
    "    },\n",
    "    \"after\": {\n",
    "        \"network\": \"nft-devnet-3\",\n",
    "        \"start_at_slot\": 0,\n",
    "        \"finish_at_slot\": 2000\n",
    "    }\n",
    "}\n",
    "\n",
    "# Validate and process the config\n",
    "config = process_config(config)\n",
    "\n",
    "# Load environment variables\n",
    "credentials = load_env()\n",
    "db_url = create_db_url(credentials)\n",
    "\n",
    "# Initialize Clickhouse client\n",
    "clickhouse = ClickhouseClient(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "Let's collect block arrival data from both networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for nft-devnet-2 (before RLNC)...\n"
     ]
    },
    {
     "ename": "DatabaseException",
     "evalue": "Orig exception: Code: 47. DB::Exception: Unknown expression or function identifier `index` in scope SELECT slot, MAX(index) AS highest_index FROM beacon_api_eth_v1_events_blob_sidecar FINAL WHERE (meta_network_name = 'nft-devnet-2') AND ((slot >= 0) AND (slot <= 2000)) GROUP BY slot ORDER BY slot ASC. (UNKNOWN_IDENTIFIER) (version 25.3.2.39 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m before_block_data \u001b[38;5;241m=\u001b[39m clickhouse\u001b[38;5;241m.\u001b[39mfetch_block_arrival_times(\n\u001b[1;32m      5\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      6\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      7\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinish_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m before_head_data \u001b[38;5;241m=\u001b[39m clickhouse\u001b[38;5;241m.\u001b[39mfetch_head_arrival_times(\n\u001b[1;32m     11\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     12\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     13\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinish_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m before_blob_data \u001b[38;5;241m=\u001b[39m clickhouse\u001b[38;5;241m.\u001b[39mfetch_blob_data(\n\u001b[1;32m     17\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     18\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     19\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinish_at_slot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Fetch data for the \"after\" network (NFT-Devnet-3)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (after RLNC)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/go/src/github.com/ethpandaops/xatu-data/analysis/pectra/rlnc_arrivals/./scripts/clickhouse.py:115\u001b[0m, in \u001b[0;36mClickhouseClient.fetch_blob_data\u001b[0;34m(self, network, start_slot, end_slot)\u001b[0m\n\u001b[1;32m     97\u001b[0m query \u001b[38;5;241m=\u001b[39m text(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124m    SELECT\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124m        slot,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124m    ORDER BY slot ASC\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m\"\u001b[39m: network,\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_slot\u001b[39m\u001b[38;5;124m\"\u001b[39m: start_slot,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_slot\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_slot\n\u001b[1;32m    113\u001b[0m }\n\u001b[0;32m--> 115\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1385\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   1382\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m   1383\u001b[0m     )\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:334\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1577\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1565\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1567\u001b[0m )\n\u001b[1;32m   1569\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1570\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1571\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1576\u001b[0m )\n\u001b[0;32m-> 1577\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1591\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1592\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         ret,\n\u001b[1;32m   1597\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1953\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1950\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1953\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2138\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2134\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   2135\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m   2136\u001b[0m         )\n\u001b[1;32m   2137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2138\u001b[0m         \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/util/compat.py:211\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    208\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1910\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1908\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1910\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1915\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1916\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1917\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1922\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/base.py:416\u001b[0m, in \u001b[0;36mClickHouseDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 416\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:117\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, parameters, context)\u001b[0m\n\u001b[1;32m    114\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_id}\n\u001b[1;32m    115\u001b[0m response_gen \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mexecute(raw_sql, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_query()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py:216\u001b[0m, in \u001b[0;36mCursor._process_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response):\n\u001b[1;32m    214\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(response)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(response, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m response\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:133\u001b[0m, in \u001b[0;36mRequestsTransport.execute\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    Query is returning rows and these rows should be parsed or\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    there is nothing to return.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     lines \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39miter_lines()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/envs/ldm/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py:179\u001b[0m, in \u001b[0;36mRequestsTransport._send\u001b[0;34m(self, data, params, stream)\u001b[0m\n\u001b[1;32m    177\u001b[0m     orig \u001b[38;5;241m=\u001b[39m HTTPException(r\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    178\u001b[0m     orig\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatabaseException(orig)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mDatabaseException\u001b[0m: Orig exception: Code: 47. DB::Exception: Unknown expression or function identifier `index` in scope SELECT slot, MAX(index) AS highest_index FROM beacon_api_eth_v1_events_blob_sidecar FINAL WHERE (meta_network_name = 'nft-devnet-2') AND ((slot >= 0) AND (slot <= 2000)) GROUP BY slot ORDER BY slot ASC. (UNKNOWN_IDENTIFIER) (version 25.3.2.39 (official build))\n"
     ]
    }
   ],
   "source": [
    "# Fetch data for the \"before\" network (NFT-Devnet-2)\n",
    "print(f\"Fetching data for {config['before']['network']} (before RLNC)...\")\n",
    "\n",
    "before_block_data = clickhouse.fetch_block_arrival_times(\n",
    "    config['before']['network'], \n",
    "    config['before']['start_at_slot'], \n",
    "    config['before']['finish_at_slot']\n",
    ")\n",
    "\n",
    "before_head_data = clickhouse.fetch_head_arrival_times(\n",
    "    config['before']['network'], \n",
    "    config['before']['start_at_slot'], \n",
    "    config['before']['finish_at_slot']\n",
    ")\n",
    "\n",
    "before_blob_data = clickhouse.fetch_blob_data(\n",
    "    config['before']['network'], \n",
    "    config['before']['start_at_slot'], \n",
    "    config['before']['finish_at_slot']\n",
    ")\n",
    "\n",
    "# Fetch data for the \"after\" network (NFT-Devnet-3)\n",
    "print(f\"Fetching data for {config['after']['network']} (after RLNC)...\")\n",
    "\n",
    "after_block_data = clickhouse.fetch_block_arrival_times(\n",
    "    config['after']['network'], \n",
    "    config['after']['start_at_slot'], \n",
    "    config['after']['finish_at_slot']\n",
    ")\n",
    "\n",
    "after_head_data = clickhouse.fetch_head_arrival_times(\n",
    "    config['after']['network'], \n",
    "    config['after']['start_at_slot'], \n",
    "    config['after']['finish_at_slot']\n",
    ")\n",
    "\n",
    "after_blob_data = clickhouse.fetch_blob_data(\n",
    "    config['after']['network'], \n",
    "    config['after']['start_at_slot'], \n",
    "    config['after']['finish_at_slot']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Now let's process the data to calculate metrics for both networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for before network\n",
    "before_combined = process_block_data(\n",
    "    before_block_data, \n",
    "    before_head_data\n",
    ")\n",
    "\n",
    "before_blobs = process_blob_data(before_blob_data)\n",
    "before_metrics = calculate_arrival_metrics(before_combined, before_blobs)\n",
    "\n",
    "# Process data for after network\n",
    "after_combined = process_block_data(\n",
    "    after_block_data, \n",
    "    after_head_data\n",
    ")\n",
    "\n",
    "after_blobs = process_blob_data(after_blob_data)\n",
    "after_metrics = calculate_arrival_metrics(after_combined, after_blobs)\n",
    "\n",
    "# Add network label for visualization\n",
    "before_metrics['network'] = 'before_rlnc'\n",
    "after_metrics['network'] = 'after_rlnc'\n",
    "\n",
    "# Combine for easier comparison\n",
    "all_metrics = pd.concat([before_metrics, after_metrics], ignore_index=True)\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"Dataset summary:\")\n",
    "print(f\"Before RLNC ({config['before']['network']}): {len(before_metrics)} slots, {before_combined['meta_client_name'].nunique()} unique clients\")\n",
    "print(f\"After RLNC ({config['after']['network']}): {len(after_metrics)} slots, {after_combined['meta_client_name'].nunique()} unique clients\")\n",
    "\n",
    "# Compare the networks\n",
    "comparison = compare_networks(before_metrics, after_metrics)\n",
    "\n",
    "# Show improvement for key metrics\n",
    "print(\"\\nOverall improvement in arrival times:\")\n",
    "for metric in ['min_arrival_time', 'p50_arrival_time', 'p95_arrival_time']:\n",
    "    before_avg = comparison[metric]['before']\n",
    "    after_avg = comparison[metric]['after']\n",
    "    diff = comparison[metric]['difference']\n",
    "    pct = comparison[metric]['improvement_percent']\n",
    "    \n",
    "    print(f\"{metric.replace('_arrival_time', '')}: {before_avg:.1f}ms → {after_avg:.1f}ms ({diff:.1f}ms improvement, {pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Overall Block Arrival Time Comparison\n",
    "\n",
    "Let's create visualizations to compare the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot(metrics_df, metric='p50_arrival_time', title=None, subtitle=None):\n",
    "    \"\"\"\n",
    "    Create a box plot comparing before and after networks for a specified metric.\n",
    "    \n",
    "    Args:\n",
    "        metrics_df (DataFrame): Combined metrics from both networks\n",
    "        metric (str): The metric to plot\n",
    "        title (str, optional): Title for the plot\n",
    "        subtitle (str, optional): Subtitle for the plot\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure with the plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create box plot\n",
    "    sns.boxplot(\n",
    "        x='network', \n",
    "        y=metric, \n",
    "        data=metrics_df,\n",
    "        palette={'before_rlnc': 'skyblue', 'after_rlnc': 'lightgreen'},\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(\n",
    "        x='network', \n",
    "        y=metric, \n",
    "        data=metrics_df,\n",
    "        color='gray',\n",
    "        alpha=0.4,\n",
    "        jitter=True,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Network', fontsize=14)\n",
    "    ax.set_ylabel(f'{metric.replace(\"_arrival_time\", \"\")} Block Arrival Time (ms)', fontsize=14)\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=16, pad=20)\n",
    "    \n",
    "    # Set x-axis labels\n",
    "    ax.set_xticklabels([f'Before RLNC\\n({config[\"before\"][\"network\"]})', \n",
    "                         f'After RLNC\\n({config[\"after\"][\"network\"]})']\n",
    "                      )\n",
    "    \n",
    "    # Add grid for readability\n",
    "    ax.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add average line\n",
    "    before_avg = metrics_df[metrics_df['network'] == 'before_rlnc'][metric].mean()\n",
    "    after_avg = metrics_df[metrics_df['network'] == 'after_rlnc'][metric].mean()\n",
    "    \n",
    "    ax.axhline(before_avg, color='blue', linestyle='--', alpha=0.5, xmin=0, xmax=0.25)\n",
    "    ax.axhline(after_avg, color='green', linestyle='--', alpha=0.5, xmin=0.75, xmax=1)\n",
    "    \n",
    "    # Add text for averages\n",
    "    ax.text(0, before_avg, f'Mean: {before_avg:.1f}ms', \n",
    "            ha='right', va='bottom', color='blue', fontweight='bold')\n",
    "    ax.text(1, after_avg, f'Mean: {after_avg:.1f}ms', \n",
    "            ha='left', va='bottom', color='green', fontweight='bold')\n",
    "    \n",
    "    # Add improvement percentage\n",
    "    if before_avg > 0:\n",
    "        improvement_pct = (before_avg - after_avg) / before_avg * 100\n",
    "        improvement_text = f'Improvement: {improvement_pct:.1f}%'\n",
    "        ax.text(0.5, (before_avg + after_avg) / 2, improvement_text,\n",
    "                ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    # Add branding if title and subtitle are provided\n",
    "    if title and subtitle:\n",
    "        fig = add_branding(fig, title, subtitle)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create box plots for different metrics\n",
    "metrics_to_plot = ['min_arrival_time', 'p05_arrival_time', 'p50_arrival_time', 'p95_arrival_time']\n",
    "for metric in metrics_to_plot:\n",
    "    title = f\"{metric.replace('_arrival_time', '').title()} Block Arrival Time Comparison\"\n",
    "    subtitle = \"Reed-Solomon Linear Network Coding (RLNC) Impact\"\n",
    "    \n",
    "    fig = create_boxplot(all_metrics, metric, title, subtitle)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Time Series Analysis\n",
    "\n",
    "Let's plot the arrival times over time to see any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries_plot(before_metrics, after_metrics, metric='p50_arrival_time', window=100):\n",
    "    \"\"\"\n",
    "    Create a time series plot with rolling average for both networks.\n",
    "    \n",
    "    Args:\n",
    "        before_metrics (DataFrame): Metrics for the before network\n",
    "        after_metrics (DataFrame): Metrics for the after network\n",
    "        metric (str): The metric to plot\n",
    "        window (int): Window size for rolling average\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: The plotly figure\n",
    "    \"\"\"\n",
    "    # Sort by slot\n",
    "    before_metrics = before_metrics.sort_values('slot')\n",
    "    after_metrics = after_metrics.sort_values('slot')\n",
    "    \n",
    "    # Calculate rolling averages\n",
    "    before_metrics['rolling_avg'] = before_metrics[metric].rolling(window=window, min_periods=1).mean()\n",
    "    after_metrics['rolling_avg'] = after_metrics[metric].rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add scatter plots for raw data\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=before_metrics['slot'],\n",
    "        y=before_metrics[metric],\n",
    "        mode='markers',\n",
    "        name=f'Before RLNC ({config[\"before\"][\"network\"]})',\n",
    "        marker=dict(color='royalblue', size=5, opacity=0.5),\n",
    "        hovertemplate='Slot: %{x}<br>Arrival Time: %{y:.1f}ms'\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=after_metrics['slot'],\n",
    "        y=after_metrics[metric],\n",
    "        mode='markers',\n",
    "        name=f'After RLNC ({config[\"after\"][\"network\"]})',\n",
    "        marker=dict(color='green', size=5, opacity=0.5),\n",
    "        hovertemplate='Slot: %{x}<br>Arrival Time: %{y:.1f}ms'\n",
    "    ))\n",
    "    \n",
    "    # Add rolling average lines\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=before_metrics['slot'],\n",
    "        y=before_metrics['rolling_avg'],\n",
    "        mode='lines',\n",
    "        name=f'Before RLNC Rolling Avg ({window} slots)',\n",
    "        line=dict(color='navy', width=3),\n",
    "        hovertemplate='Slot: %{x}<br>Rolling Avg: %{y:.1f}ms'\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=after_metrics['slot'],\n",
    "        y=after_metrics['rolling_avg'],\n",
    "        mode='lines',\n",
    "        name=f'After RLNC Rolling Avg ({window} slots)',\n",
    "        line=dict(color='darkgreen', width=3),\n",
    "        hovertemplate='Slot: %{x}<br>Rolling Avg: %{y:.1f}ms'\n",
    "    ))\n",
    "    \n",
    "    # Add horizontal lines for overall averages\n",
    "    before_avg = before_metrics[metric].mean()\n",
    "    after_avg = after_metrics[metric].mean()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[before_metrics['slot'].min(), before_metrics['slot'].max()],\n",
    "        y=[before_avg, before_avg],\n",
    "        mode='lines',\n",
    "        name=f'Before RLNC Average: {before_avg:.1f}ms',\n",
    "        line=dict(color='navy', width=2, dash='dash'),\n",
    "        hoverinfo='name'\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[after_metrics['slot'].min(), after_metrics['slot'].max()],\n",
    "        y=[after_avg, after_avg],\n",
    "        mode='lines',\n",
    "        name=f'After RLNC Average: {after_avg:.1f}ms',\n",
    "        line=dict(color='darkgreen', width=2, dash='dash'),\n",
    "        hoverinfo='name'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': f\"{metric.replace('_arrival_time', '').title()} Block Arrival Time Over Time\",\n",
    "            'y': 0.95,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(size=20)\n",
    "        },\n",
    "        xaxis_title=\"Slot Number\",\n",
    "        yaxis_title=\"Arrival Time (ms)\",\n",
    "        legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),\n",
    "        hovermode='closest',\n",
    "        plot_bgcolor='white',\n",
    "        height=600,\n",
    "        width=1000\n",
    "    )\n",
    "    \n",
    "    # Add improvement annotation\n",
    "    if before_avg > 0:\n",
    "        improvement_pct = (before_avg - after_avg) / before_avg * 100\n",
    "        fig.add_annotation(\n",
    "            x=0.5,\n",
    "            y=1.05,\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            text=f\"Overall Improvement: {improvement_pct:.1f}%\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=16, color=\"black\"),\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            bordercolor=\"rgba(0,0,0,0.5)\",\n",
    "            borderwidth=1,\n",
    "            borderpad=4\n",
    "        )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create time series plots for different metrics\n",
    "for metric in metrics_to_plot:\n",
    "    fig = create_timeseries_plot(before_metrics, after_metrics, metric)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by Blob Count\n",
    "\n",
    "Let's analyze how the number of blobs affects the arrival time improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blob_count_comparison(before_metrics, after_metrics, metric='p50_arrival_time'):\n",
    "    \"\"\"\n",
    "    Create a comparison of arrival times grouped by blob count.\n",
    "    \n",
    "    Args:\n",
    "        before_metrics (DataFrame): Metrics for the before network\n",
    "        after_metrics (DataFrame): Metrics for the after network\n",
    "        metric (str): The metric to plot\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: The plotly figure\n",
    "    \"\"\"\n",
    "    # Group by blob count\n",
    "    before_by_blob = before_metrics.groupby('blob_count').agg({\n",
    "        metric: ['mean', 'std', 'count'],\n",
    "    }).reset_index()\n",
    "    \n",
    "    before_by_blob.columns = ['blob_count', 'mean', 'std', 'count']\n",
    "    \n",
    "    after_by_blob = after_metrics.groupby('blob_count').agg({\n",
    "        metric: ['mean', 'std', 'count'],\n",
    "    }).reset_index()\n",
    "    \n",
    "    after_by_blob.columns = ['blob_count', 'mean', 'std', 'count']\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    merged = pd.merge(before_by_blob, after_by_blob, on='blob_count', how='outer', suffixes=('_before', '_after'))\n",
    "    \n",
    "    # Calculate improvement\n",
    "    merged['improvement'] = merged['mean_before'] - merged['mean_after']\n",
    "    merged['improvement_pct'] = (merged['mean_before'] - merged['mean_after']) / merged['mean_before'] * 100\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                         subplot_titles=(\n",
    "                             f\"{metric.replace('_arrival_time', '').title()} Arrival Time by Blob Count\",\n",
    "                             \"Improvement Percentage by Blob Count\"\n",
    "                         ),\n",
    "                         row_heights=[0.6, 0.4],\n",
    "                         vertical_spacing=0.1)\n",
    "    \n",
    "    # Add bar chart for mean arrival times\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=merged['blob_count'],\n",
    "            y=merged['mean_before'],\n",
    "            name=f'Before RLNC ({config[\"before\"][\"network\"]})',\n",
    "            error_y=dict(type='data', array=merged['std_before'], visible=True),\n",
    "            marker_color='royalblue',\n",
    "            text=merged['count_before'],\n",
    "            hovertemplate='Blob Count: %{x}<br>Arrival Time: %{y:.1f}ms<br>Sample Size: %{text}'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=merged['blob_count'],\n",
    "            y=merged['mean_after'],\n",
    "            name=f'After RLNC ({config[\"after\"][\"network\"]})',\n",
    "            error_y=dict(type='data', array=merged['std_after'], visible=True),\n",
    "            marker_color='green',\n",
    "            text=merged['count_after'],\n",
    "            hovertemplate='Blob Count: %{x}<br>Arrival Time: %{y:.1f}ms<br>Sample Size: %{text}'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add improvement percentage as line chart in second subplot\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=merged['blob_count'],\n",
    "            y=merged['improvement_pct'],\n",
    "            name='Improvement %',\n",
    "            marker_color=['green' if x > 0 else 'red' for x in merged['improvement_pct']],\n",
    "            text=[f\"{x:.1f}%\" for x in merged['improvement_pct']],\n",
    "            textposition='auto',\n",
    "            hovertemplate='Blob Count: %{x}<br>Improvement: %{y:.1f}%'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add zero line to second subplot\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        y0=0,\n",
    "        x1=merged['blob_count'].max() + 0.5,\n",
    "        y1=0,\n",
    "        line=dict(color=\"black\", width=1, dash=\"dash\"),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Impact of RLNC on {metric.replace('_arrival_time', '').title()} Arrival Time by Blob Count\",\n",
    "        xaxis=dict(title=\"Blob Count\"),\n",
    "        xaxis2=dict(title=\"Blob Count\"),\n",
    "        yaxis=dict(title=\"Arrival Time (ms)\"),\n",
    "        yaxis2=dict(title=\"Improvement (%)\"),\n",
    "        legend=dict(x=0.01, y=0.99, bgcolor='rgba(255,255,255,0.8)'),\n",
    "        barmode='group',\n",
    "        height=800,\n",
    "        width=1000,\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create blob count comparison plots for different metrics\n",
    "for metric in metrics_to_plot:\n",
    "    fig = create_blob_count_comparison(before_metrics, after_metrics, metric)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile Analysis\n",
    "\n",
    "Let's analyze the impact on different percentiles of arrival times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentile_comparison():\n",
    "    \"\"\"\n",
    "    Create a comparison of arrival times at different percentiles.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The figure with the plot\n",
    "    \"\"\"\n",
    "    # Define percentiles to compare\n",
    "    metrics = [\n",
    "        'min_arrival_time', 'p05_arrival_time', \n",
    "        'p50_arrival_time', 'mean_arrival_time', \n",
    "        'p95_arrival_time', 'max_arrival_time'\n",
    "    ]\n",
    "    \n",
    "    # Get average values for each percentile\n",
    "    before_values = [before_metrics[m].mean() for m in metrics]\n",
    "    after_values = [after_metrics[m].mean() for m in metrics]\n",
    "    \n",
    "    # Calculate improvements\n",
    "    improvements = [(b - a) / b * 100 if b > 0 else 0 for b, a in zip(before_values, after_values)]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), height_ratios=[3, 1], gridspec_kw={'hspace': 0.3})\n",
    "    \n",
    "    # Shortened labels for x-axis\n",
    "    labels = ['Min', 'P05', 'P50', 'Mean', 'P95', 'Max']\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Plot bars for arrival times\n",
    "    rects1 = ax1.bar(x - width/2, before_values, width, label=f'Before RLNC ({config[\"before\"][\"network\"]})', color='skyblue')\n",
    "    rects2 = ax1.bar(x + width/2, after_values, width, label=f'After RLNC ({config[\"after\"][\"network\"]})', color='lightgreen')\n",
    "    \n",
    "    # Add value labels\n",
    "    def add_labels(rects, values):\n",
    "        for rect, val in zip(rects, values):\n",
    "            height = rect.get_height()\n",
    "            ax1.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                    f'{val:.0f}ms',\n",
    "                    ha='center', va='bottom', fontsize=10, rotation=0)\n",
    "    \n",
    "    add_labels(rects1, before_values)\n",
    "    add_labels(rects2, after_values)\n",
    "    \n",
    "    # Set up first subplot\n",
    "    ax1.set_ylabel('Arrival Time (ms)', fontsize=14)\n",
    "    ax1.set_title('Block Arrival Time by Percentile', fontsize=16)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(labels)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot improvement percentages in second subplot\n",
    "    bars = ax2.bar(x, improvements, width, color=['green' if i > 0 else 'red' for i in improvements])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, improvement in zip(bars, improvements):\n",
    "        height = bar.get_height()\n",
    "        y_pos = height + 1 if height > 0 else height - 5\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., y_pos,\n",
    "                f'{improvement:.1f}%',\n",
    "                ha='center', va='bottom' if height > 0 else 'top', \n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Set up second subplot\n",
    "    ax2.set_ylabel('Improvement (%)', fontsize=14)\n",
    "    ax2.set_title('Percentage Improvement by Percentile', fontsize=16)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(labels)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add overall title\n",
    "    fig.suptitle('RLNC Impact Across Different Percentiles', fontsize=18, y=0.98)\n",
    "    \n",
    "    # Add branding\n",
    "    fig = add_branding(fig, \"RLNC Performance Improvement\", \"Impact on Different Percentiles of Block Arrival Times\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create percentile comparison\n",
    "fig = create_percentile_comparison()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
